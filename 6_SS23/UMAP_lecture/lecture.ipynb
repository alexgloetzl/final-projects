{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP Lecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP stands for Uniform Manifold Approximation and Projection and is a dimensionality reduction method. In biology we often deal with thousands of genes per cell. This makes each cell a point in a 1000-dimensional space or also called feature space. If we want to plot a cell with its 1000 genes we need to first reduce those 1000 dimensions or features down to only 2 or 3 since our human brain cannot visualize much more than that. \\\n",
    "Take care however that those reduced features do not necessarily correspond to the original genes in the cell but are more likely a combination of all the previous 1000 genes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the famous *iris* data set of 3 different kinds of flower species. Each flower type has 4 different features, namely sepal length, sepal width, petal length and petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>5.4</td><td>3.9</td><td>1.7</td><td>0.4</td><td>setosa</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & setosa\\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & setosa\\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & setosa\\\\\n",
       "\t4 & 4.6 & 3.1 & 1.5 & 0.2 & setosa\\\\\n",
       "\t5 & 5.0 & 3.6 & 1.4 & 0.2 & setosa\\\\\n",
       "\t6 & 5.4 & 3.9 & 1.7 & 0.4 & setosa\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | Sepal.Length &lt;dbl&gt; | Sepal.Width &lt;dbl&gt; | Petal.Length &lt;dbl&gt; | Petal.Width &lt;dbl&gt; | Species &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 5.1 | 3.5 | 1.4 | 0.2 | setosa |\n",
       "| 2 | 4.9 | 3.0 | 1.4 | 0.2 | setosa |\n",
       "| 3 | 4.7 | 3.2 | 1.3 | 0.2 | setosa |\n",
       "| 4 | 4.6 | 3.1 | 1.5 | 0.2 | setosa |\n",
       "| 5 | 5.0 | 3.6 | 1.4 | 0.2 | setosa |\n",
       "| 6 | 5.4 | 3.9 | 1.7 | 0.4 | setosa |\n",
       "\n"
      ],
      "text/plain": [
       "  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n",
       "1 5.1          3.5         1.4          0.2         setosa \n",
       "2 4.9          3.0         1.4          0.2         setosa \n",
       "3 4.7          3.2         1.3          0.2         setosa \n",
       "4 4.6          3.1         1.5          0.2         setosa \n",
       "5 5.0          3.6         1.4          0.2         setosa \n",
       "6 5.4          3.9         1.7          0.4         setosa "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(\"iris\")\n",
    "\n",
    "head(iris)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) PCA - Principal Component Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to visualize each row of our table, i.e. each sample, in a 2 dimensional scatter plot. Therefore we calculate the first and second principal component of this data set. The first principal component is again a combination of our 4 features that specifically lies in the direction of the highest variance. The figure below shows the spread of the features in a 2D space and the corresponding direction of the principal components for a made-up data set (not our iris data set yet)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of first two principal components of an arbitrary artificial data set. Notice how the first principal component (PC1) shows in the direction of the highest spread/variation of the data.\n",
    "\n",
    "![](./lecture_plots/pca_components.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same but for our iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1h0E9oaGh8fHyMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnfU2vh4eHp6enw8PD///+JrwZJAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3diZqiuhZA4aA4lbbI+79sy6AMMmcnZFj/d+851ZYSqpp1GEWVA9Cm9p4BIASEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGE5AFVS073z0OP87H481/zpMv7CZc95g4FQvKAatSpnL5tPTpP2msOwa/eA62QVBlO2nrgWT3nr/zD39RkYBAheeCzqrknSp3zcn2U3F55nt3e3zlVz3m39d64S/ebycgRkge+22zP8qv3P5OsfuB4rb7K3o/l792mbKdZjB4heaDZ+Sm/eq95bv2nvB+75lcON+yGkDzQXiMl5Vbcz4rnvdH3yl/lt7EHQvJAbx9p4Ojcvdo9eu883fvfghWE5AHVPUg3EFJd0P177AGWEZIHWh3d86GQvtt05RYedkBIHvhUlF7KSo7fk0cft1ZqP8chYAMheaC3Cvo9andshXS0OWf4ICQP9EJ6NOeRHuV5pEd7J0o9hiYBwwjJA/2dou+VDdfqyoZLc23QjVNJ+yAkD/RDeiXN+qdYN6nmEMOLK1f3wW/dAz9xvL5XrR6z8nrV8/dbJ65c3QUheWDoDOz5vVY6nsvTr2n7NOydK1d3QUiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECLISkAM9sWMrlw9lhiOWcmhk4ipBmOTUzcBQhzXJqZuAoQprl1MzAUYQ0y6mZgaMIaZZTMwNHEdIsp2YGjiKkWU7NDBxFSLOcmhk4ipBmOTUzcBQhzXJqZuAoQprl1MzAUYQ0y6mZgaMIaZZTMwNHEdIsp2YGjiKkWU7NDBxFSLOcmhk4ipBmOTUzcBQhzXJqZkb8+/dv71mIXIAh3aXmouZ+SP8qe89G1MIL6Sg9f4SEeb6EtPw2LVvu5zI9QeHpifv3j5J250dIa+54REjYgd8h3VOl0mqf6HZUye3z1PqB4633rPtJqeSiOTPOISQHeBHS2E34btWjRS6n8qu0CSn9PNB61rX6amVJzofEPpIDvA4pUc88/1PH96pGpa/8lar7Z9PuTyXP/Jmov/azVPHHv7XbfoSEeV6HpNTnUPdJvd7/fKnTJ6RT+a17tY66916lNTNOIqO9eRHS2D7SRanT89l6QvGU6mn1k4t/Nc/K8+x+TUMMCXvzOqT8mrwfTbLpkJpn1TtOhARxfoQ0fh7pfjlWez+tZzb//PyrftZZHW/3jJAgz5eQpp6sPrtE3z82+0in9sPltwgJBngd0rE6CnesD9Llt+pgQ7ER1zpq1zxLqUf+ZB8JBngd0l+1y/PIP3s/xY7Q8f2vvH0eqXnWRTUvEJ8ZRM3rkKprFqosbu+AzsW66HEsQ8pvSefKhvJZ5+KL1vae6MwgZn6HZIVTMwNHEdIsp2YGjiKkWU7NDBxFSLOcmhk4ipBmOTUzcBQhzXJqZuAoQprl1MzAUYQ0y6mZgaMIaZZTMwNHEdIsp2YGjgo/pNFrVJdevEpImEdI8xMQmxWEy5eQDNyUgJAgx4+QjNwmh5Agx+OQXsV79fLiDUiv5v6Q7zxex+J9Et+7Qla9XBKVZuXTvzeO7N1H8vPC2ZkBfnkR0sitRNPyvbBZ8e697/0h3z2ciltANneFbG4Xmbzy9hv+eveRrF84OzPAAJ9D+lPXvLh96r17f8i06KV9V8jii/eD5yKT1lvQq2+0/li+cHZmgAE+h5SX23ZH1bs/ZPle2OaukNW9UR7Ft5PejSN7fxx5BzohYZ4XIY0dbDi/t+2yYj3zc1u7zr0j28cVWrfpan2j+5yZmQF+eR3S471tdylWJL8hte8dSUgwzo+Qxs4jJcfif50Imi9b944kJBjmS0jDLupWHnD4uT9k6w/F/9OffaRTdx/pREjQ4ndI2XvzrTjM0Lk/ZPmd9l0hi++kr3d1M0ftNGcGMfM7pHcvafnv5v6QdQ/NXSGXn0fSnRlEzPOQ/j7bdN/7Q356+N4Vsr6yQalTfWVD0r2yoftHnZlBxDwPyQanZgaOIqRZTs0MHEVIs5yaGTiKkGY5NTNwFCHNcmpm4ChCmuXUzMBRhDTLqZmBowhpllMzA0cR0iynZgaOIqRZTs0MHEVIs5yaGTgqjJCGr5PrPrr07lvaM4MYEZL4zCBGvoR0OBzMDzuMkDDPj5AOFfMDDyEkzPM4pNadVqu3lNd3Sr0k6tK6KUN2UknxdvTeHVfvJ6WSoftBzs4M8MuLkA6HwZKaO61WyVR3Si3f83puQiruJlTc2KH7Ttlr9Q7aJSUREub5HFJzp9UqmfJOqff6LgzfkN6P3n7vuKqqezos+VkICfN8Dqm502qVTHmn1M99gTqPfv7U3HG1ngAhQYYXIY0dbGjdafUbxeCN63q3sStl92tKSBDidUitO62uDin93Jp19cwAv/wIaew8UvtOq+tCOqvj7Z4REoT4EtKwz51WW5H87CPlre83d1wtHyckSPE7pM+dVlsh/Ry1y1vfb+64WhyEeLKPBCl+h/S502p7sy3tfDBFN6TmPNJFfW/FKjYziJjnIdV3Wu3s/xQXLzxGQmruuHoubsR6H/zQ2K0zg4h5HtL4FFKB2agnJTYlhCu4kMpLFl6nRRf/GJ8ZWcOfEQUn2AzpVWxO1Te9n97N11h264vokvlnLuVISCOfWgg3WAzpVV4+Wu+VGAspv6VKHeXWR4SEJSyGdFG3d0235HucTX4II9yYmbFPdocbLIaUVC/MkmNGSKsRktsshvRp55WmQyGpto1DGOHGzBCS2yyGdCwvQii/SlkjrUZHTrMY0k2d668yNXNxjiPLbsWRmSEkp9k8/H351nOf2XpzZNmtODMzZOQwqydkn98LcrIzISEkwV3ZIM+pmYGjCGmWUzMDRxHSLKdmBo4ipFlOzQwcRUiznJoZOIqQZjk1M3CUoyE5xfzPC+85GpL5IQBJhOQ0LmbwBSE5jMvr/EFIDiMkfxCSu3gLkkcIyV2E5BFCchcheYSQHEZH/iAkhxGSPwjJaWTkC0LCF9luR0gR64bDhqQOQopWPxxC0kFI0eqFw8F2LYQUq344hKSFkGJFSKIIKVY/4dCRDkKKlsmDDYfDQWQ6/iCkaP2GI5jRIbaUCClipjbkCMnUSxwcAsYcDhGWREiQRkjGXuLgEDCGkIy9xMEhYE6EHRES5BGSqZc4OARMii0jQoK4OK+OICSIivVCI0KCKEIy+RIHh4AR0V5DTkiQREhGX+LgECHbcTkmJKMvcXCIcHWW5NFF2tQB6kg7IqTwtBbl0aXa3ClTQjL5EgeH8MfKxbK9cbVDSJxHMvkSB4fwxer/wrdCGt1hifKyUrMIyXGE5AdCctuGo2A/W3aEZAEhuU0rpH32keJESG7bdF6mffCbkOwgJMdpHk62fh4pVoTkuFjPy/iGkJxHRj4gJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJOjgbHGNkLAd1y99ERK2I6QvQsJmm97jEShCwmaE1CAkbEZIDUKKi+xST0dfhBQT6QWfkL4IKSbyCz4Z1QgpfP17obDsG0BIofu9OxchGUBIoSMkKwgpcJ146MgYQgocIdlBSIHrbc6RkSGEFDrWQlYQUugIyQpCCh8ZWUBIgABCAgQQEiCAkAABhAQIICRAACHBgPg+WJOQIC7Gj3omJIgjJFMvcXAIGHM4RFgSIUEaIRl7yU5DKEWRPTauuyMkYy/ZZQhVkZhUKCxdCR5hR4QUFUIyJtyQlKKkHns3P4ktI0KKCncRMoeQIkJI5oQbUoz7SHON0JExhBSO+UwIyZiAQ4ruPNKSTMjIkKBDisu/f+wD7YeQgvHvHynth5CCQUh7IqRwUNKOCCkchLQjQgrJ0pAITZzFkFSXiSGw5Bg46ywDLIZ0mw5pcWWYQkj7sLlp90xS2SEobsjC64QoSZTVfaSnuggOwcprG0Iywe7Bhpt6yg1BSNsQkgn+HrVjf2or0x1F2SghxcdsSJGu7ggpRobXR4Rk6iVGhhjriLb2FOseWHAhsZra17KQwrs5ischDa97CGlfS0IK8XZdOiG9zkql9/pB0UV3+8TYc9rbghUSIXVe8krKJfZUPUhIKC1eIYVVkkZIF3V713SrrvshJE9YOAywYAeJkFovSaovsuSYuRMS+0iTnDiiRkjdl3yW1leaEpInnAiJfaTuS47q9fkqdSckziNNcOQkDyF1XnJT5/qrTKUOhYRRjoTEeaTuSy7feu7CawFCMsNCSOElsozWCdnn6fNVdiYkH5juKMSNtmW8vrIBS7TDISRTCClwrXTKf5nerou1JEIK3DckG4cZCMnwSxwcIhLN4QVCMoqQwvbvh9Hhou2IkAJHSJYQUuB6W3bGz8XGmVFEIcV64ZDVgw0R0wzpu3QmicTcDA0hM8GfS1njCas5+O1rSD6s5YRCyhy/RKgfUpTXiPubkQf7XRoh3Tu3vT/uPFfT0+u/3S/KkEwztLQHH1J+bHf02HmupqfXC4n30coztbx7cm5Kah9JFiH5h5AsvGT3IUY6IiQxxpZ3QtJgKyTpYSJmbnn3oiPtkK5HEwul2fNIrJAMICStl1zNLJRml3A6MsHg8u5+RtohJcW97eQRkj8+Z6f8WHEYE8dRu/7kex3R1Gbt6yUizkg7pNP3llyirIbE6kmDxxceydIMKUtS0TOxA0MYoaK8XEh+iXfm/l670960c/xgw/yMRbPH1F/kJRZ/QvoIO6QlsxZpSDIBENJH2CdkCanRW+Z1A6iPLNBRLeiQljUSR0e9kDRXJd9j3YRU0w7pfiqWwVMmND9DQ2yfDCE1zITk7bucpOmGlFbLoEpES7IaUiznkYa27DZG4MmFpDZphnRT6atYCptPphBhcx8pGoIHGwjph/YlQq/q6gZ/j9pFpHfwm5AECVwi5HBIsWy1baJ5zI6OOjRDOtZrpKfb92yAMELqk9lHugtfBW4wJFZRMsioS/eo3aneDUmlZuh3CNEJs9MEI0TOI6nTn9DsDA6x4PlL2yAku+JZb4VwZcPiOsxcGIgxMe1JRRRS6wJbQrKCkKRfYnSIFdcvkJJNUZ1tCuAuQgvbUIRk2U9IITcVwF2EtoUUZklOXUHaCyns1VMIdxHasmUXZEiuvaehm04/pLCiCuEuQhsONhBS92UzD2w0tEIKdf0Uxl2EFnURS0crK/h5jeR6rbuDREijL/HrLkKqusaWkAZeNfGAjG5IwR3RC/PmJ9OzE2ZGcyGNPP7zIs33zo6b2tDzX4ghhbvOmTFRwOi3CElGACdkf19NSMu/ZS+k7nG6wDoKMaSQjyfMmdiumylp4gEjCKn3kr/i9id7X/3dfXHEIY1xLyTOIw3cRUg59X6koA9xbzS5vfbzsI2MQqP9Dtnk/v6XW++Q7R8BISn3LnoIjvY9G57lv526Z0M3JNZOBUIyTOoSIZcOf3e37gipwm6PUWJrpERmfn6H2DaBb0jsMFkT2oG4VULcR8oJybayH0LSeImDR+2qKfS27AjJ4KbdocvUME7TP4/kwl2EBqbAwYYOowcbCCnIKxs+02gOfhOS0ZAOhBRySK2pRZ+R2Y+opKNcatPufBeancEhoI2QTJM62HCSmqHfIaDPaEjN4bpoM9IO6eLo4W/02DjYYGbintC+i5CDlwih0M1mbUgro4s9o1AvEcJvOCszWp4dl/AVtDftPmsk0Z0kEyHFdexOb1Nuxau5Graifcvich/pkbh2ZcPPFOM6mzR3cGF60V9zaIKQKnI3P5FcTglJ03QKcwv/vxatgdbyeFcrkpBiu+JuOoQ1Ic0kIhlSc/DPw6BiuLIhjy+kyQV8fuHfNyQvj6YTUpimOpj+VvfVS0sSmGW/L9mLJKTY9pGW3Dfo91uthx0Iya+SdEO6JCb+W09I2hZs2808vnSrTSajyEO6yB9o6A8hNs2YMsq33Ha1X47cymaZmENSLnzQGIZMZrBok2+nkKI82ODEB41h2NoIfrflbGZU+B78ji6kixsfNAYRtldBo7zLSOD9SGkmNStjQ8AWZ0LykG5Id28ONmABoYwirFEzpKs/R+1gS5QrNu039nHUzm8TS/zWGAhp/Us4aue39SebFk8zspK0N+04aucziyF5eCRuDe039qUPqVkZGwLGTKw8tq9XBl/p5bmhNeTejyQ2Szkh2bI5pMkmhl5ISNMvISSvbQxpporxFVLAJcXyNgoM2raPNBvF0A4SIQm8pPa4nqrbsl5mdqwIyZJNIW2ogpBmX/JX3LR40ce6vI6tDcHpuw4ZCSm291Ess+E80pYqQu/I5geNXVTyV90FL7sn6iI8V3Oie2ffdnOH6uINaeIn0AxpzUdffm5vXJj5zFlC2s/cUe+tb7wLIqPxH1szpOOKe38rNfaH+hFDhwC7UxefcmhMheQ/kyGtufe3nTXSSCuEtNDcidhoM5r5ycXWSJNhlIqPgKnevGRuH2m0FkJaiJDGGA1pzT7S98BE4Th5jZ58SOwjLbQqpKh6MhrSmqN2ef64lOeRktPV0HmkifUOIS00s4/0r16a/oVyJG45k/tI9WfILjqPtHmIFa+b2oBbmlHkuS082JATUkdYlwgJ7Amx5pr9zJdiffQvyr0lc+eRDDGwj2RvCsGrQ4swpAlaIWXn8hDD6yj9fvP9QuLo3mKE1KYTUpZUH3h5VyqRvSmX/HmkFS8npIXoqEUnpKM6VwexH6nsh5qLbT2uD4KQliOkFo2Q7ur6feykRI/bySzG7SQWp0FHK5DRl0ZI59aNT7JlJ5LWDqE5lW8TK+ogJGyhEdLMRag6RCbW2kpbVQcZYT2NkBJvQmLHB6Zpbdrdv4/dq+N3UggJntEI6dkc9M4Spw82EBJM0zn8fVHJtXgXxfOayB5r2PNgA7CF1pUNzWdRnAVnKZcKqTluQEgwTO9au+xS3kPoKv1hY0beai4+TeArsItWRydIRzAqipDYsoNpEYdEWpATQ0iDR79ZS22w5VNeWkK+NI+QsNTWD0yqWbpYfKda4wqpKYdztOvJhGR2Qd/trR0xhNS9iavqPiQ7UsjmbtQ149AmO2e/oxib/ihCwkI2Q9rawn5vf9d6G8Xv8rnfXM1M8OfSVTpaSzKk6QV9ewyEpD1XCyZKSHrE9pEIaetLnBhiYOvOxDDhshWSTg3sI1kYwszaMyYbMmq/ZN0KKc6QHu69se93qpRk289KzHRI3p5Huvizj5RzrM66ga3BZcfs9lmtaNAMqenoPvr8DQgpDBsP9EUYUvEW81RlWapmPqhl+xCi6MiqzUfMfctIO6Rimby+10ZPF+9rNzRhQrJJ89STTwRCuhef1ufHPlLOQW+7tnYU3RqpuFVxpo75w5uQsIrm2mRbSBHuI92LgMqPvxS9/QkhuUFgw2zj+ii2kN47SHlxq8jpDynXG8IONvkG7LOHY/k6H5mBYrqyYWrA5iAERX0JHCvYspSuDUmrBKlmCaka8BMSh/VatEPatpSuC0mzBGdCKj/V/Cx6OlY2pCVZNCdqCallp5ByiyGJbUbqhpTWS57opXaCIS0LQ/0QmwGvSV3vbfB1miW4EtJFJcXK6J4o0c9jHpur9Us4IekgpMW0LxF6lv9+yn6I7PBcbVjGF4XRyoeQenSPNLgekiv7SK278mjPysgQ7cFMhNRdD9GRpK1LaXwHGy7fNZL59yNtWVt0ttWGX9rdnCMkSR6E5Mp5pGu5j/RILHw+0qbNrp+tttmpkpGkrUvpmtfJlKBJe9POyC66gZDGXsxe0QpRXMe9jUchbdvsmiuJkBaL5i0RW/h0ZYORkNgrWmwwJMqq+BTStv2Xhauk1dONztB1DqykPjRC6nxeuLvvR/rM3viMktEihDQl/JA+oZiZ04gMhBTRW8nn+LVppzdRQtIzukISD2nJAW0nDno3CAlL2QppySlWqQsSxOiG9Lok738ml5fQ/AwMITdVOtI0dMxOfoUUY0hZUu9/JJnUHPWHWPiK5e862jJDGGZwhTRZidhF22I0Q0rVuVgXvS4WrrWbev7CRMhopflIjOwgxReS1au/J57PusYEd+99ElxIiap2jl67hsRhBDO2hqQZ328jv8W41pH+2yjS4qbfj1T2flyE5IKNx+S012P9SIaiCS2k7z0bLLyNYuLphGTCXiH110DD0TiVkdRdhFLROzYI7CMRlYBtIYmfW3Jvf2hIGCdkeyGxfpKhs0IiJBMvMT9Ef320ICRSm0NIy4USUufVS3aZWGstsfGY3ZKOJsrofcuHjvTv2XB07+pvQtrVopAm4vj5VgwhXc28OcF8SBzoM6iT0XAC8yH1DoBLz6M07ROywsfrfofY8vLFKyRCMmwkmIn9nkObjVmUIXWJkCxCCgUhLXvJScm+f2JgiG0TWHq7b92BMGmsiKUh+VOS9tsoykuEpNk4MEhIFowGsWgfKaKQmmMNDh1sWDoIGRlHSAtf4nNIsGC8h4lKPOwoyBOycMfWIAhJBCGFY2sOXmUUx33toIGb1i1DSJjA/R+XYtMOEwhpKd0TsqLvMB8cAvsxdSfVfRnZ+wryEiEICTEkQ8cDNUM6OnqJEEQQ0mKaIb1Ovl4ihCWC7Ui8JK5swARCWoqQojYfSVgZORuSIYRkhdj6xqfaDF3IR0gREwpJevtv7G1KYlM3kZJOSNklUdKfjNQbAgZJHZOTDWlwGRdd8F0LqfhsJCX9yUjdIWCSUEjCx8jNh2RkR0kjpLNKX/krVWe5uekPAZOcDGlwGZde8N0KqfpIl0wlcnPTHwJGiW7ZEdLWl9RHvE1cJURIVrh4sMFKSAYub4gnJG7RMEDq4LdXBxsMTC+ekLhpkEnCB7/NhyR/CTghwTW/y7iJ49XCtELq2HmuZibIjVV9Rkj25mpmgoTks7BDMoiQ0OF8R7GExD6S3wip/brlm4KEhB63M7Ia0m33kMSnCtRsbto9k9T0EGPTY320H611iesroi+r+0hPtfDuXYQUjCV7N6Pfd3/X6MvuwYabepoeYnByHLPbzXwLE88gpA2MnZQipB0tOAM0/gQPTh99uROSwSHMJYoZ8y1MPOPgUUlRhGRybYdJQiG5n9IeIc0vy4QUjJEOmoemUiGk6QlYD4mtu90MdtB5cP5ggw8lxRJSziGHvQyvjxaF5NFuEiHBun4cG3ehnBJRSJyWdcWqOPzoiJBgHyFtfYn1IUZ6ISM3rIvDg4wCDYkDdI7zZC2zRuAhDaREXi4ILKMwQ5o6/cqaCkYEH5Ia/J7W9IEfkYXEzhPMCDGkiW07QoIZwYc08h29AYCeIEOaOABORzAi0JCqqQwf/CYkyAs5pJFpkxHkxRcSYAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQmoG5a4o2IyQPkNyny5oIKTPkIQEDYRUj8i9jKGDkOoRCQk6CKkekZCgg5A+Q9IRNBDSZ0hCgoZ4QpqthIywXSwh9Vc4VANRcYbEdhyERRJS76AcIUFYlCFxrBvSCAkQEElI3Y05QoK0KENiHwnSYgmpe8CbkCAsnpB6I5ARJMUaEiCKkAABhAQIICRAACEBAggJEEBIgABCAgQQEiCAkAABhAQIICRAACEBAggJEEBIgABCAgQQEiCAkAABhAQIICRAACEBAggJEEBIgADPQ+L2dHCD1yFxw1S4gpAAAT6HxIdKwBmEBAggJECAzyGxjwRnRBQSycEcr0NaEwdrL5jkeUgrJklIMCiWkDgwAaMICRBASICAWEJiHwlGERJ8djgc9p6FSjQhcR4pQIfK3rNRiCgkBIeQ9h8C/jsc3CmJkOCtWEN6nZVK7/VEJqdCSFgg0pBeSXnc7FRNhJCgzZ2ObIZ0Ubd3TbckLSdCSNAWZ0hJ9cIsOWaEBBmOZGQ1pE87rzQlJATGYkhH9fp8lRISwmIxpJs6119lKiUkBMXm4e/Lt577zOU6hATPWD0h+zx9vsrOP1NRbZuHAHbBlQ2AAEICBOwR0vyWGyHBM4QECCAkQAAhAQIICRBASIAADn8DAggJEEBIgIDgQuJCPewhsJC45hX7ICRAQFgh8TYM7ISQAAGEBAgIKyT2kbATQgIEBBYS55Gwj+BCAvZASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQkJQDofDLuMSEgJyqOwwMiEhIIRkfQgE6HDYrSRCQjgIyf4QCBAh2R8CIWIfyfoQCBEhWR8C4Winw3kky0MgFPuthdoICZ4jpF2HQCB2PFLXRkjwGyHtOwQCQUjWhlCKMAPmREcRhKQqglOEUwjJzhCEFLz9M4ogJKUoCeYREiCAkAABwYfEPhJsICRAQPghcR4JFsQQEmAcIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECHA0J8MyGpVw+nF3GsDsQP5IPA1ndFiIkt0fiR/JiJEJyfSR+JC9GIiTXR+JH8mIkQnJ9JH4kL0YiJNdH4kfyYiRCcn0kfiQvRiIk10fiR/JiJEJyfSR+JC9GIiTXR+JH8mIkQnJ9JPdv5ZYAAAXTSURBVH4kL0YiJNdH4kfyYiQuzQZEEBIggJAAAYQECCAkQAAhAQIICRBASIAAQgIEEBIggJAAAYQECCAkQAAhAQIICRBASIAAGyG9zkqdnxYGym9HlVxeNkZ6j2X+V3dJgvpxymFs/Q3ZW+gqNn59SXmDfws/1KUcKLGy6D23fGTBOmn54xxND1Oy8OMU7P0NWVvoahZ+fRd1Lv5xMj7QU51fxX9az8ZHeo+VGF/yHip5FuM8DI9TsPDjlMNY+xuyttB9WPj1Jar4D5CFv6hTNYSNReKmUuPDXNT9/c8/dTU8Tm7nxynY+xuyttB92LvlRWJtJAs/k7qYH+aksrz4j7iF/6ra+HHaw9kay95CZy2ki7pZGumlUvODPC0sDcreCtbGj9Ow8jdUsLfQ2QrpT73/m2fJrdwiMi+kkOwNU7D0N2RzobMV0u2U2NjUL2SJpR1MQtrI1t+QxYUut7iPdLazmn0lljYbCGkje39D1ha6gsFfX/fzoV/mdvzaA6VGT7u0RzK+5CVhhmT2b6jL4ELXZy0kg39TzUDZMc1MjdIdycKSVx21yyydC7EUkum/oR57G6zWziNlFk7R320dDioY/zu6lvvkd0t7zHYWOWt/Q/YWupqtKxteJ/Obq5nNjswveTavbLAUkr2/IWsL3Ye9a+3M/wrPSvU2J00yP8zR0u+tZOW3ZvFvyNZC92HnUsVEHS38p0EFFtKrvPrb9Cg1K781m39Dlha6D96PBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJGOqz6ZLzln7obGnjk+k9YfnOVHnu9Ds9fQme2PBWIfflzGfj3lMstZDY08dn0jz9aWa3jEbe7KGY3cOnpY+PzQc/L6MqZbFV6p0Pga2tUBfVfJebbyu7TLFdMN5JoS0Er8vY+pl8aUS/Ym8ZZ+AzsUn30vrhHNTKSGtxO/LmM+yWPxbqddRneovs5NKruW3LolKs+9T3ttu9YeY30+q/rJZoC+qek3+OpUf1n071p/a/X7KtZzge9Pvkncn1H5WM+z7waT7YPejxt+TIaSV+H0Z014jKXVS9eL5TqRYaotFOi13oV6fkK7FH9O82IgrXfJ2SKl6tqdevrZ8dv3Ce1q/pjWhzrO+w55+H+yG9Jzaa8Mgfl/GVMtillYLd/rKP8G8v7ypY57/FV+dq2+XC/Wz2Dn5K778K76r8vYC3V20/9rPLidY/TPpTOj3We9h78VX7123e/vBfjiEtBK/L2O+R+3KVc6jeujzZfHVqfiqXmEV/y+OQN/fG4Df1+fjIZ3qZ6fNBJttxO+EBp5VPFg0/Sq+3zxISJr4fRnTPo9UL5fNIttdeFt/qtdj92s6GdLgBH8mNDJsbXhehkbDLH5fxrSXxZUhpZ8lvfWc03cf6f4iJOfw+zJme0hndbzds15I189Ru0drn2ZbSL3ZIiQB/L6MmQ0p7e0jFfsr9+IkUfmUfkjf80ipujV7P6ehkL4TGnxW9WDef9H4zGMBfl/GzIZ0K46ZXfpH7e5VCs/+PtJ7PVVc2VCc+Ml7x+OaEXoTGnxW+eB78FP3Rd3LJQhpJX5fxsyG1D+PVP6xOGhXX1RXrFnaE0nb19q1zxDlebeJ74SGn5V+LwFsHjyq7gUYhLQSvy9j5kMqijm1rmw41VchvFc+Kn20tshqf6f343/1H25Jc2VD3g2pmdDws27vbFoHE4t/Po6EpIXflyvEFl0a2AO/dFcQktf4pbuCkLzGL90VhOQ1fumAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIICQAAGEBAggJEAAIQECCAkQQEiAAEICBBASIOA/ZyKsQnWiHzYAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"PCA\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pc <- prcomp(iris[,-5], center = TRUE, scale. = TRUE)\n",
    "\n",
    "plot(pc$x[,1], pc$x[,2], col=iris[,5], pch=16, xlab=\"Principal Component 1\", ylab=\"Principal Component 2\", main=\"PCA\")\n",
    "legend(\"topleft\", legend=levels(iris$Species), col=1:3, pch=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully reduced our 4 dimensional data set into a 2 dimensional space. For visual guidance the class of the samples was manually added, otherwise it would be hard for the viewer to confirm a good clustering result. PCA does not classify the samples by itself. Just like UMAP it is a unsupervised machine learning algorithm that means that no labels or classes (in our case flower species) are presented to the algorithm. Notice how for the iris data set only two variables, here PC1 and PC2, are enough information to separate our data decently into distinguishable clusters.\n",
    "\n",
    "Similar to PCA, UMAP can also reduce the 4 dimensions down to only 2 dimensions. The method of UMAP is harder to understand and more sophisticated than simply looking at the direction of maximal variation. On the other hand the results of UMAP currently often show best clustering results among the dimensionality reduction algorithms. \\\n",
    "When applying UMAP <a id='first_umap_figure'></a> to the iris data set tighter clusters and more separation between labels can be observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"UMAP\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(umap)\n",
    "\n",
    "iris.umap <- umap(iris[,-5])\n",
    "\n",
    "plot(iris.umap$layout[,1], iris.umap$layout[,2], col=iris[,5], pch=16, xlab=\"Axis 1\", ylab=\"Axis 2\", main=\"UMAP\")\n",
    "legend(\"topright\", legend=levels(iris$Species), col=1:3, pch=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging on the quality of a dimensionality reduction algorithm is not super straight forward when trying to compare results of for example PCA and UMAP. The idea is that the high dimensional structure should be preserved as best as possible in the low dimensional space (often 2D or 3D). For now better separation and tighter clusters shown by UMAP will suffice.\n",
    "\n",
    "Interestingly UMAP manages to find clusters that are both more separated and also more dense and therefore make for easier separation between clusters. This could be useful if the goal would be to label certain clusters. Later we will learn how we can influence clustering result of UMAP, i.e. if we want to emphasis on retaining global or local structure in the low dimensional space. \\\n",
    "Also notice how the axes of the plot no longer have any mathematical meaning anymore, unlike in PCA where they corresponded to the variance in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) UMAP - High dimensional represenatation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before UMAP can reduce the dimensionality of the data set it has to construct a so called graph of the data. A graph relates the structure of the data in real space. For example if two samples are close together because they have similar values in all of their features then the graph would show a strong connection between those two points. \\\n",
    "We are going to look at the graph that UMAP constructs on the artificial data of a sinus curve. Although this sinus curve is only in 2 dimensions, it is supposed to represent the high dimensional space that we want to reduce, i.e. to a single dimension in this case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/how_umap_works_raw_data.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UMAP algorithm starts off by looking for its k-nearest neighbors for each of the above data points. Visually one can think of this as constructing a sphere around each data point where this sphere includes only the k-nearest neighbors (including the middle point itself as one of the k neighbors as well). \\\n",
    "Following figure shows this process for k=5 nearest neighbors. Each circle should only contain 5 points in total."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/how_umap_works_local_metric_open_cover.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have a connection between each point and its 5 nearest neighbors (itself included). Now we would like to assign an importance to some of those connections, also called edges, between two points. \\\n",
    "If two points are particularly close together in our data set we want them to have a strong connection/edge and if they are further apart within the circle then they should have a weaker edge. We can express this strength of the edge by a number called *weight*. The higher the weight the closer together two samples are. \\\n",
    "In practice one can achieve this variation in strength by introducing an exponential decay with increasing distance from the center point. \\\n",
    "The next figure visualizes this exponential decay with a higher saturation in the center and a fading towards the circumference.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/how_umap_works_fuzzy_open_cover.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we have to consider now is, that in high dimensional spaces the distance between two arbitrary points tend to be almost the same. This is called the *curse of dimensionality* and describes the phenomenon that the distance of one sample to its next nearest neighbor is almost the same as its 10-nearest neighbor. \\\n",
    "Hence we would like to clearly distinguish between the next nearest neighbor and the rest. UMAP implements this by assigning the nearest neighbor an edge weight of 1, i.e. fully connected, and after this nearest neighbor the edge weight decreases exponentially as before and finally becomes zero when reaching the edge of the circle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/how_umap_works_umap_open_cover.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all that is left to do is draw a line for each point to its k-nearest neighbors (itself included) and make the strength of the connection between two points visible by different linewidths.\n",
    "The connection strength for each point to its nearest neighbor is always the same, namely 1. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/how_umap_works_umap_graph.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the graph theory from above and look at concrete numbers of distance and edge weights. For this we look again at only a 2 dimensional artificial data set, that we want to reduce to a 1 dimensional space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph construction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by finding the k-nearest neighbors of each data point. Before we start the UMAP algorithm we have to choose a k value. For simplicity reasons let's choose $k=3$ but we could have picked any other value $k$ as well as long as it is bigger than $1$. Looking at the figure below it is clear that the nearest neighbor of sample A is B & C. Nearest neighbor for B is A & C and so on. \\\n",
    "The UMAP algorithm finds these nearest neighbors by picking one sample and calculating the distance to all other samples (itself included). The three shortest distances constitute the 3 nearest neighbors. This process is then repeated for each sample. \\\n",
    "In the figure below the distance between sample A and B is 0.5. This value of 0.5 is for example calculated like this with the given features of A and B:\n",
    "\n",
    "Point A = (0.32, 1.65) \\\n",
    "Point B = (0.1, 1.2)\n",
    "\n",
    "Therefore the (euclidian) distance between them is: \\\n",
    "$d_{AB} = \\sqrt{(0.1-0.32)^2 + (1.2-1.65)^2}\\approx 0.5$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/step00.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the distances between samples we just calculated, we want to assign edge weights to the k-nearest neighbors. Remember that those edge weights represent how strong the connection between two given points are. \\\n",
    "We start by looking at the point A and draw a circle around it. In 3 dimensions we would draw a ball or for $n$-dimensions $> 3$ we would use a n-hypersphere. \\\n",
    "The edge weight up until the nearest neighbor, here it is point B, is always equal 1. For the rest of the k-nearest neighbors (here only point C is left) the edge weight decreases exponentially. \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/step012.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge weights $w_{high}(x_i, x_j)$ in the high dimensional space are calculated like this:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Large w_{high}(x_i, x_j) = \\exp(-\\frac{d(x_i, x_j)-d_{\\text{nearest neighbor}}}{\\sigma_i})\n",
    "    \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "with $x_i$ and $x_j$ being the respective points at the end of the edge, e.g. point A & B. $\\sigma_i$ is the decay constant that is different for each point $i$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the edge weights from the perspective of point B, i.e. we want to calculate $w_{high}(B,A)$ and $w_{high}(B,C)$. We can think of the above equation like this:\n",
    "\n",
    "![](./lecture_plots/exp_new.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that $w_{high}(B,A) = 1$ because A is the nearest neighbor to B. For the edge weight $w_{high}(B,C)$ is given by:\n",
    "\n",
    "$\\Large w_{high}(B,C) = \\exp(-\\frac{2.0-0.5}{\\sigma_i})$\n",
    "\n",
    "In order to calculate $\\sigma_i$ we need another formular:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Large \\sum_{j=1, j\\ne i}^{k} \\exp(-\\frac{d(x_i, x_j)-d_{\\text{nearest neighbor}}}{\\sigma_i}) = log_2(k)\n",
    "    \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "This constraint tells us that all the edge weights summed up should equal the logarithm (in base 2) of k.\n",
    "\n",
    "Let's again plug in our numbers here for the example of point B:\n",
    "\n",
    "\\begin{aligned}\n",
    "    \\large w_{high}(B,A) + w_{high}(B,C) = log_2(3) &\\approx 1.6 \\\\[9pt]\n",
    "\n",
    "    \\large \\exp(-\\frac{0.5-0.5}{\\sigma_B}) + \\exp(-\\frac{2.0-0.5}{\\sigma_B}) &\\approx 1.6 \\\\\n",
    "\n",
    "    \\large 1 + \\exp(-\\frac{2.0-0.5}{\\sigma_B}) &\\approx 1.6\n",
    "\\end{aligned}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example of $k=3$ nearest neighbors it is pretty clear that $w_{high}(B,C)$ has to be 0.6. But imagine we have $k=4$ nearest neighbors, where the distance between point B & D is $d(B,D)=1.7$, for example:\n",
    "\n",
    "$\\Large 1 + \\exp(-\\frac{2.0-0.5}{\\sigma_B}) + \\exp(-\\frac{1.7-0.5}{\\sigma_B})\\approx 1.6$\n",
    "\n",
    "Here it is not so obvious anymore what the edge weights $w_{high}(B,C)$ and $w_{high}(B,D)$ are (of course $w_{high}(A,B)$ is still 1). We can calculate the edge weights by solving this equation analytically but with the numerical power of computers there is actually a better way of solving the above equation, which we will discuss in the next paragraph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we could now solve this equation for $\\sigma_B$ analytically but what UMAP does is, it guesses what $\\sigma_B$ might be, plugs this guess in the equation above and compares its result with the target value of 1.6. \\\n",
    "Then if the guess was too low $\\sigma_B$ is increased. Otherwise $\\sigma_B$ is decreased. This turns out to be a much faster way than calculating $\\sigma_B$ by hand especially with more than k=3 nearest neighbors. This procedure is called *binary search*.\n",
    "\n",
    "Let's do an example for point B again:\n",
    "\n",
    "We want to find a $\\sigma_B$ that solves the equation:\n",
    "\n",
    "$\\Large \\exp(-\\frac{2.0-0.5}{\\sigma_B}) \\approx 0.6$\n",
    "\n",
    "We start off with a guess of $\\sigma_B = 2$ randomly.\n",
    "\n",
    "$\\Large \\exp(-\\frac{2.0-0.5}{2}) \\approx 0.47$\n",
    "\n",
    "This result is lower than our target value of 0.6 therefore we increase $\\sigma_B$ to 4.\n",
    "\n",
    "$\\Large \\exp(-\\frac{2.4-0.5}{4}) \\approx 0.69$\n",
    "\n",
    "Since 0.69 is bigger than our target we know that $\\sigma_B$ is between 2 and 4. By repeating this process we finally reach our target value of 0.6 numerically without ever solving the equation analytically. At the end of our binary search we reach\n",
    "\n",
    "$\\sigma_B \\approx 2.94$\n",
    "\n",
    "With our decaying constant $\\sigma_B$ we can now calculate the high dimensional edge weights according to equation 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to graph construction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have calculated the edge weights for all the edges connecting to point B, namely $w_{high}(B,A)=1$ and $w_{high}(B,C)=0.6$. We can do the same for point A and C."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/cluster_single_weights.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the edge weights between point B and C differ, depending from which side you look at the edge. UMAP tries to combine those two different edge weights. But instead of simply taking the average of those two edges UMAP applies the so called *fuzzy union*. A fuzzy union is the percentage of at least one of the edges existing and is given by this formula:\n",
    "\n",
    "$\\text{fuzzy union}(x,y) = 1 - (1-x)*(1-y) = x + y - x*y$\n",
    "\n",
    "For our example that corresponds to:\n",
    "\n",
    "$\\text{fuzzy union}(w_{high}(A,B), w_{high}(B,A)) = 1 + 1 - 1 * 1 = 1$\n",
    "\n",
    "$\\text{fuzzy union}(w_{high}(A,C), w_{high}(C,A)) = 0.6 + 0.6 - 0.6 * 0.6 = 0.83$\n",
    "\n",
    "$\\text{fuzzy union}(w_{high}(B,C), w_{high}(C,B)) = 1 + 1 - 1 * 1 = 1$\n",
    "\n",
    "Now we assign our newly calculated edge weights $w_{high}$ to the corresponding edges (green bonds in figure below) and we get the following graph:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/edge_weights_combined.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now finished with our high dimensional represenation of our data. We have drawn edges between the k-nearest neighbors and assigned appropriate weights to those edges. The higher the edge weight value, the stronger the connection between two points is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) UMAP - Low dimensional representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set the the high dimensional represenatation of our data set (our graph from above) aside and focus on how our data should look like in the low dimensional case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the low dimensional case the data has to be initalized. That means we take our points from the high dimensional space and place them in the low dimensional space, similar to PCA. However UMAP does not use PCA but a different method as we will see. After initialization the sample points are then moved in the low dimensional space to best capture the structure of the high dimensional case. There are two ways to initalize our data, namely spectral embedding and random initalization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Embedding & Random initializaton"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral embedding uses the graph layout of the high dimensional case, creates a normalized Laplacian matrix and then calculates the eigenvectors of the matrix. These eigenvectors are then used to represent the data in the low dimensional case. \\\n",
    "The mathematical details of spectral embedding are not important in order to understand UMAP. However it can be proven that for UMAP this spectral embedding provides a faster convergence and greater stability of our data. \\\n",
    "Below is the spectral embedding of the iris data set. The flower types are already separated quite well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/spectral_embedding_iris3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison a random initialization would look like this:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/random_iris2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to note here is that the random initialization works just as well as the spectral embedding does. However with a random initialization the process for the UMAP algorithm to finish will take longer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the low dimensional representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return now to the artificial data set with only 6 points. We have used spectral embedding to reduce the 2 dimensions down to only 1 dimension."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/spectral_embedding_2d.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the high dimensional case we now have to determine the low dimensional \"edge\" weights or membership strength. The higher the low dimensional weight between two points is, the stronger the connection between them is. \\\n",
    "However unlike in the high dimensional case where we assigned an edge weight of value 1 to the nearest neighbor and an exponentially decaying edge weight to the rest of the k-nearest neighbors, we now need a differentiable function, i.e. without a kink. We specifically need a differentiable function for the low dimensional weights because later we will take the derivative of it, which is not possible for a non-differentiable function.\n",
    "\n",
    "The function for the low dimensional weights is defined as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Large w_{low}(y_i,y_j) = (1 + a(|y_i - y_j|)^{2b})^{-1}\n",
    "    \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "with $a = 1.93$ and $b=0.79$. The variables $y_i$ and $y_j$ are two points in the low dimensional space. Therefore $|y_i - y_j|$ gives the distance between two points in the low dimensional space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the low dimensional weight\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above for the low dimensional weight function uses $a = 1.93$ and $b=0.79$. However those parameters are not set in stone and can be changed to vary the outcome of the UMAP algorithm. The low dimensional weights are quite similar to the definition of the high dimensional weights. We can see this by inspecting the following equation. It shows the low dimensional edge weight function on the left and a sort of \"representation of the high dimensional edge weight\" in the low dimensional space.\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "  (1 + a(|y_i - y_j|)^{2b})^{-1} \\approx\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if $|y_i - y_j| \\le$ min\\_dist}\\\\\n",
    "      \\exp(-|y_i - y_j|+\\text{min\\_dist}) & \\text{otherwise}\n",
    "    \\end{cases}     \n",
    "    \\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "The *min_dist* (minimal distance) is an important parameter that defines the local connectivity of the points in the low dimensional space. It basically says how closely points can be packed together in low dimensions. \\\n",
    "Low values of min_dist will result in densely packed low dimensional representations because two points need to be much closer together to be considered *close* than for a higher values of min_dist. High values of min_dist will make the data look more spread out in low dimensions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the left and right hand side of equation 4, we can gain some insight into why the low dimensional weight function was defined as it is. Therefore we will plot the right hand side of equation 4 with a *min_dist* $=1$ for a number of distances $|y_i - y_j|$ from 0 to 10. Then we will use the parameters $a$ and $b$ of the low dimensional weight function $w_{low}(y_i,y_j, a, b)$ to best fit this line.\n",
    "\n",
    "<span style=\"color:blue\">Blue dots</span>: curve of the right-hand side of equation 4. This can be looked at as a resemblence of the high dimensional edge weights in the low dimensional space. However this is not a formal definition and more of an intuitive way of understanding the plotted line. The kink shows the *min_dist* $=1$ parameter. \\\n",
    "<span style=\"color:red\">Red line</span>: the low dimensional weight function $w_{low}(y, a, b)$ as a fit to the blue dots. Parameters $a$ and $b$ were fitted as to most closely approximate the blue line."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/min_dist.png)\n",
    "\n",
    "We can see that by finding the correct parameters $a$ and $b$ the low dimensional weight function $w_{low}(y, a, b)$ closely resembles the high dimensional exponential decay of the edge weights after passing the nearest neighbor. For the plot above the parameters, that minimize the error of the fit for a *min_dist* $=1$, actually are $a=0.12, b=1.88$. As mentioned above UMAP chooses $a = 1.93$ and $b=0.79$ by default, which resembles more closely a *min_dist* $=0.1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to optimization of low dimensional space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "With our low dimensional weight function $w_{low}(|y_i - y_j|)$ we can now assign a connection strength or weight for two points in the low dimensional space. \\\n",
    "Going back to the data set with 6 points, we can imagine putting point A at the center $(|y_A - y_A|=0)$ of the low dimensional weight function $w_{low}(|y_i - y_j|)$. If we then want to know the \"edge\" weight between point A and for example point B, we have to look at the function value (ordinate axis value) of $w_{low}(|y_A - y_B|)$. \\\n",
    "So far so good but how does UMAP now optimize the distances in low dimensional space? The UMAP algorithm picks at random any edge in high dimensional space (high edge weights are more likely to be picked). For our example let's pick the edge weight $w_{high}(A,B)$. Then again UMAP picks at random any one of those two points, i.e. point B. UMAP tries to put point B closer to point A because A is one of B's nearest neighbors (in the high dimensional space). Simultanously UMAP also picks a point that is not one of point B's k-nearest neighbors, i.e. point E, and tries to maximize the distance between point B and E. In summary UMAP tries to shift B closer to A because they are in the same neighborhood but further away from point E because they are not in the same neighborhood in the high dimensional space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/step13.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the figure above it is not clear why UMAP does not just shift B on top of A, therefore minimzing the distance between point A and B and also having a high distance between point E and B. Instead of finding the \"optimal\" solution to the shifting of B, UMAP only moves point B a little step into the correct direction. This has the advantage of being computationally far less demanding and eventually after several iterations returning the optimal solution as well. \\\n",
    "Finding the correct shift direction of point B requires the minimization of the cost function, called cross entropy (CE):\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Large \\text{CE}(w_{high}, w_{low}) = \\\\\n",
    "    \\sum_i \\sum_j [ w_{high} \\log(\\frac{w_{high}}{w_{low}(d_{ij})}) + (1- w_{high}) \\log(\\frac{1-w_{high}}{1-w_{low}(d_{ij})})] \n",
    "    \\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "with $d_{ij} = |y_i - y_j|$ for the low dimensional distance between point $i$ & $j$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high dimensional edge weights $w_{high}$ stay constant because they are only dependent on the real space distance between samples and those do not change. Therefore we can for now ignore the high dimensional edge weights $w_{high}$ in the cost function. When minimizing the distance between point A and B $w_{high}(y_A, y_B)$ is high because they are in the same neighborhood ($w_{high}(y_A,y_B)=1$ even). Therefore when setting $w_{high}$ of the left part of the cost function above to 1, it simplifies to:\n",
    "\n",
    "$\\Large w_{high} \\log(\\frac{w_{high}}{w_{low}(d_{ij})}) + 0 \\rightarrow \\log(\\frac{1}{w_{low}(d_{ij})})$\n",
    "\n",
    "Similarily for the right part of the cost function when trying to push point B away from point E $w_{high}(y_E,y_B)$ is close to 0 because point E is not one of the k-nearest neighbors of point B. By setting $w_{high}=0$ we can simplify the right part of CE further. It might seems strange why we put $w_{high} = 1$ when considering the same neighborhood and $w_{high}=0$ otherwise but as can be seen in the definition cost function (equation 5) we consider all edges (indicated by $\\sum_i$ and $\\sum_j$) but only pick two of those at random (edge between A B and B E for neighborhood or non-neighborhood respectively). This process of picking a subset of data or edges is a familiar theme in data science called stochastic gradient decent. It gives a less accurate result than calculating the cost function (or more precisely the slope of the cost function) over all edges but it is a lot faster and gives a good enough approximation to the true slope. By repeating this process of picking only a subset we eventually get a similar result than taking all the edges. Therefore when considering non-neighborhood the right part of CE simplifies to:\n",
    "\n",
    "$\\Large 0 + (1 - w_{high}) log(\\frac{1- w_{high}}{1- w_{low}(d_{ij})}) \\rightarrow log(\\frac{1}{1- w_{low}(d_{ij})})$\n",
    "\n",
    "Putting those two equations together gives us a reduced version of the cost function:\n",
    "\n",
    "$\\Large \\text{CE}_{red} = \\log(\\frac{1}{w_{low}(d_{ij})}) + log(\\frac{1}{1- w_{low}(d_{ij})})$\n",
    "\n",
    "We will use this cost function in the next paragraph to calculate the optimal shift of point B."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step by step example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again let's put in some numbers to make the process more clear. We need to calculate $w_{low}(y_A,y_B)$ which corresponds to the neighborhood weight. Then we calculate $w_{low}(y_E,y_B)$ which corresponds to the non-neighborhood weight. Then we plug those numbers into the simplified cost function $\\text{CE}_{red}$ from above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/step23.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** low dimensional weight between point A and B is calculated \\\n",
    "$\\Large low_{dim}(y_A,y_B) = \\frac{1}{1+a|y_A-y_B|^{2b}} = \\frac{1}{1+1.93 \\cdot 1.9^{2 \\cdot 0.79}} \\approx 0.16$\n",
    "\n",
    "**Step 2:** low dimensional weight between point A and E is calculated \\\n",
    "$\\Large low_{dim}(y_E,y_B) = \\frac{1}{1+1.93 \\cdot 2.5^{2 \\cdot 0.79}} \\approx 0.11$\n",
    "\n",
    "**Step 3:** plug above low edges in $\\text{CE}_{red}$ \\\n",
    "$\\Large \\text{CE}_{red} = \\log(\\frac{1}{w_{low}(y_A,y_B)}) + log(\\frac{1}{1- w_{low}(y_E,y_B)}) = \\log(\\frac{1}{0.16}) + log(\\frac{1}{1- 0.11}) \\approx 1.88$\n",
    "\n",
    "If we repeat this process for different positions of point B relative to point A and E (distances $d_{low}(y_A,y_B)$ and $d_{low}(y_E,y_B)$ respectively), we can plot the cost function in dependence of the position of B."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/cost_function.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As calculated above the first red cross is 1.88. The three next red crosses can be calculated in the same way with different positions of B in the low dimensional space.\n",
    "\n",
    "\n",
    "|                  | $y_A - y_B$ | $y_E - y_B$ | $w_{low}(y_A, y_B)$ | $w_{low}(y_E, y_B)$ | cost function |\n",
    "|------------------|-------------|-------------|---------------------|---------------------|---------------|\n",
    "|1st position of B | 1.9 | 2.5  | 0.16  | 0.11  | 1.88  |\n",
    "|2nd position of B | 1  | 3.4  | 0.34  | 0.07  | 1.11  |\n",
    "|3rd position of B | 0  | 4.4  | 1  | 0.05  | 0.02  |\n",
    "|4th position of B | 1  | 5.4  | 0.34  | 0.03  | 0.48  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the graph the 3rd position of point B minimizes the cost function best. Here point B sits on top of point A but UMAP only takes one optimizaton step for two edges (here edge AB and BE) and then repeats this process for two other randomly chosen edges as described above. In the end we are rewarded by a little step of B in the correct direction in the low dimensional space. A direction that best represents the structure of the high dimensional space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/spectral_embedding.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the cost function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a better intuition how the cross entropy CE (cost function of UMAP) works by plotting it. We start from the non-simplified version of the cost function:\n",
    "\n",
    "$\\Large CE(w_{high}(x_i, x_j), w_{low}(y_i, y_j)) = \\\\\n",
    "\\sum_i \\sum_j [ w_{high}(X) \\log(\\frac{w_{high}(X)}{w_{low}(Y)}) + (1- w_{high}(X)) \\log(\\frac{1-w_{high}(X)}{1-w_{low}(Y)})] $\n",
    "\n",
    "where for simplicity $X$ stands for the distance between two points in high dimensional space and $Y$ stands for the distance in low dimensional space.\n",
    "\n",
    "Plotting above equation results in a 3D plot, where the cost function of UMAP depends on the high and low dimensional distances $X$ and $Y$, respectively:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "![](./lecture_plots/cost_function_3d.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our goal is to minimize the cost function. If the high dimensional distance $X$ is large, then $Y$ should also be large. Therefore at this point ($X$ and $Y$ have large values) the cross entropy should be small accordingly. If the cost function is small, we also keep the penalty to our optimization problem small. In this case the structure of the high dimensional space is retained in the low dimensional space. You can see this low value of CE at the figure above at the point $X=3.0$ and $Y=3.0$ for example. For a fixed $X=3.0$ the CE value becomes bigger if we decrease $Y$, e.g. $Y=0.5$. Since we try to minimize the cost function $Y$ will prefer to stay at higher values and therefore keeping the penalty of the cost function to a minimum. Same is true for a small high dimensional distances $X$. There small values of $Y$ lead to a small cost function. \n",
    "\n",
    "In the plot you can also see that more than anything UMAP tries to have a high $Y$ for high values of $X$ because for small distances in low dimensional space the cost function increases rapidly (red mountain slope on the left) more so than the other way around. This can be interpreted as saying if two points are far apart in high dimensional space then UMAP tries really hard to keep it this way in low dimensional space. Therefore UMAP preserves the \"global\" structure of the high dimensional data well. The \"local\" structure would refer to small distances in the high dimensional space and therefore to the other slightly smaller mountain in the figure above. That is not to say that UMAP does not also preserve the local structure of the high dimensional space as well just that there the penalty is not quite as big."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient of the cost function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the correct direction for point B to step in, we need to find the minimum of the cost function. This is equivalent to saying we need the first derivative of the cost function and set it to 0:\n",
    "\n",
    "$\\Large \\frac{\\partial CE}{\\partial y_i} = 0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder the non-simplified cross entropy (cost function) for UMAP looks like this according to equation 5:\n",
    "\n",
    "$\\Large CE(w_{high}, w_{low}) = \\\\\n",
    "\\sum_i \\sum_j [ w_{high} \\log(\\frac{w_{high}}{w_{low}(d_{ij})}) + (1- w_{high}) \\log(\\frac{1-w_{high}}{1-w_{low}(d_{ij})})] $\n",
    "\n",
    "with $d_{ij} = y_i - y_j$ for the low dimensional distance between point $i$ & $j$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the high dimensional edge weights $w_{high}$ stay constant when varying the position of our point B in low dimensions, we can leave all the sums with only $w_{high}$ out of the derivative (slope of a constant is zero) and only focus on $w_{low}(y_i, y_j)$:\n",
    "\n",
    "$\\Large CE(w_{low}, w_{high}) = \\\\\n",
    "\\sum_j \\Bigr[ -w_{high} log(w_{high}) - (1 - w_{high}) log(1- w_{low})\\Bigr]$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next step it will easier if we write the low dimensional weights $w_{low}(d_{ij})$ out and calculate the derivative of $w_{low}(d_{ij})$:\n",
    "\n",
    "$\\Large w_{low}(d_{ij}) = \\displaystyle \\frac{1}{1+ad_{ij}^{2b}} $\n",
    "\n",
    "$\\Large 1- w_{low}(d_{ij}) = \\displaystyle \\frac{a d_{ij}^{2b}}{1 + ad_{ij}^{2b}} $\n",
    "\n",
    "$\\Large \\displaystyle \\frac{\\partial w_{low}(d_{ij})}{\\partial d_{ij}} = \\displaystyle -\\frac{2abd_{ij}^{2b-1}}{(1+ad_{ij}^{2b})^2} $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to do some math. If we plug in above equations in the derivative of the cost function and reduce some fractions, we will end up with our derivative for our cost function CE:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "\n",
    "\\begin{aligned}\n",
    "\n",
    "\\Large \\frac{\\partial CE(w_{low}(d_{ij}))}{\\partial y_i} = \n",
    "\\sum_j \\Biggr[ - \\frac{ w_{high}}{w_{low}(d_{ij})} \\frac{\\partial w_{low}(d_{ij})}{\\partial d_{ij}} + \\frac{1- w_{high}}{1- w_{low}} \\frac{\\partial w_{low}(d_{ij})}{\\partial d_{ij}} \\Biggr] &= \\\\\n",
    "\n",
    "\\Large = \\sum_j \\Biggr[\\biggl(-w_{high} (1+ad_{ij}^{2b}) + \\frac{(1-w_{high}) (1 + ad_{ij}^{2b})}{ad_{ij}^{2b}}\\biggl) \\cdot \\frac{\\partial w_{low}(d_{ij})}{\\partial d_{ij}}\\Biggr] &= \\\\\n",
    "\n",
    "\\Large = \\sum_j \\Biggr[ \\frac{2abd_{ij}^{2(b-1)}w_{high}}{1 + ad_{ij}^{2b}} - \\frac{2b (1-w_{high})}{d_{ij}^2(1 + ad_{ij}^{2b})} \\Biggr] (y_i - y_j)\n",
    "\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP now uses this derivative of the cost function to update the low dimensional distance of point B to A and E respectively as follows:\n",
    "\n",
    "$\\Large y_B = y_B - \\alpha \\cdot \\frac{\\partial CE(y_i=y_B)}{\\partial y_i}$\n",
    "\n",
    "where $\\alpha$ is the learning rate. The higher the learning rate, the bigger the steps of point B in the optimal direction. However if $\\alpha$ is too big then point B might \"overshoot\" its goal and never converge properly to its minimum."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we put everything together we can watch how the UMAP algorithm converges in the low dimensional space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/UMAP_animated_iris2.gif)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure below shows the endstate of the convergence of UMAP on the iris data set for a manually programmed UMAP algorithm. Compare this result to the very first [UMAP figure](#first_umap_figure) shown in the lecture. Unfortunately the manually programmed UMAP does not perform so well as the out-of-the-box UMAP package but you can see a clear separation of the different flower classes. Also note that the axes in UMAP are meaningless, which is emphasized by the switched position of the classes \"virginica\" and \"versicolor\" in the figure above (compared to the out-of-the-box [UMAP figure](#first_umap_figure) from the start of the lecture).\n",
    "\n",
    "![](./lecture_plots/UMAP_iter_iris200.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP hyperparamters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP only depends on two parameters, which have to be defined by the user before calling the UMAP function, namely `n_neighbors` and `mind_dist`.\n",
    "\n",
    "`n_neighbors`: This parameter specifies the number of n neighbors UMAP uses for each point as its neighbors (the point itself included). The higher the value of *n_neighbors*, the better the global structure of the high dimensional data is preserved because more points are considered neighbors to each other and therefore also stay together in the low dimensional space. If *n_neighbors* gets smaller, local structures of the high dimensional space are emphathized for the sake of maybe losing the bigger picture of the global structure. The default value is `n_neighbors`=15.\n",
    "\n",
    "`mind_dist`: This parameter determines how close together the points can be in the low dimensional space. Quite literally it is the minimal distance between points in the low dimensional space. It controls the distance to the next nearest neighbor in low dimensions. Remember the figure of paragraph [Parameter min_dist](#Parameter-min_dist). Lowering the `min_dist` value results in more densly packed regions. The default parameter setting is `mind_dist`=0.1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a better feel for these parameters, one can play around with them. For this purpose let's use a 3D point cloud of a prehistoric mammoth."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lecture_plots/mammoth_with_label.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>x</th><th scope=col>y</th><th scope=col>z</th><th scope=col>color</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 57.550</td><td>332.564</td><td>-141.840</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 74.325</td><td>333.604</td><td> 124.428</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>105.617</td><td>491.656</td><td>-148.480</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 71.060</td><td>427.958</td><td> 127.023</td><td>7</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 75.221</td><td>477.819</td><td>  97.443</td><td>6</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>105.744</td><td>489.485</td><td>-150.387</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & x & y & z & color\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t1 &  57.550 & 332.564 & -141.840 & 0\\\\\n",
       "\t2 &  74.325 & 333.604 &  124.428 & 2\\\\\n",
       "\t3 & 105.617 & 491.656 & -148.480 & 1\\\\\n",
       "\t4 &  71.060 & 427.958 &  127.023 & 7\\\\\n",
       "\t5 &  75.221 & 477.819 &   97.443 & 6\\\\\n",
       "\t6 & 105.744 & 489.485 & -150.387 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | x &lt;dbl&gt; | y &lt;dbl&gt; | z &lt;dbl&gt; | color &lt;int&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 |  57.550 | 332.564 | -141.840 | 0 |\n",
       "| 2 |  74.325 | 333.604 |  124.428 | 2 |\n",
       "| 3 | 105.617 | 491.656 | -148.480 | 1 |\n",
       "| 4 |  71.060 | 427.958 |  127.023 | 7 |\n",
       "| 5 |  75.221 | 477.819 |   97.443 | 6 |\n",
       "| 6 | 105.744 | 489.485 | -150.387 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  x       y       z        color\n",
       "1  57.550 332.564 -141.840 0    \n",
       "2  74.325 333.604  124.428 2    \n",
       "3 105.617 491.656 -148.480 1    \n",
       "4  71.060 427.958  127.023 7    \n",
       "5  75.221 477.819   97.443 6    \n",
       "6 105.744 489.485 -150.387 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mammoth <- read.csv(\"../data/mammoth_small_with_labels.csv\")\n",
    "\n",
    "head(mammoth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(umap)\n",
    "\n",
    "mammoth_3d <- mammoth[,-4]\n",
    "mammoth_color <- mammoth[,4]\n",
    "\n",
    "# play around with the hyperparameters\n",
    "# for example change:   n_neighbors = c(10, 20, 50, 100, 200)\n",
    "#                       min_dist = c(0.01, 0.1, 0.05)\n",
    "\n",
    "# apply UMAP (takes about 30 seconds)\n",
    "mammoth_2d <- umap(mammoth_3d, n_neighbors=15, min_dist=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"UMAP on Woolly Mammoth\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 600,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the 2D low dimensional space (embedding)\n",
    "options(repr.plot.width=10, repr.plot.height=10)\n",
    "plot(mammoth_2d$layout[,1], mammoth_2d$layout[,2], col=mammoth_color, pch=19,\n",
    "        main=\"UMAP on Woolly Mammoth\", xlab=\"\", ylab=\"\", cex=0.5, cex.main=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your computer is too slow or you do not want to wait 30 seconds for the algorithm to converge, you can also check out this website programmed by Andy Coenen and Adam Pearce [https://pair-code.github.io/understanding-umap/](https://pair-code.github.io/understanding-umap/). It is highly interactive and gives some very nice insight into how UMAP visualizes different data sets. If you scroll down a bit there is also the mammoth data set example present."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of changing the `n_neighbors` paramter:\n",
    "\n",
    "![](./lecture_plots/anim_nearest_neighbours_works.gif)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of changing the `min_dist` paramter:\n",
    "\n",
    "![](./lecture_plots/anim_min_dist_works.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strengths of UMAP \n",
    "\n",
    "Before UMAP was created an algorithm called t-SNE was the go-to dimensionality reduction technique for visualization purposes. t-SNE and UMAP are very similar in how they work and are therefore often compared to one another. However UMAP is better than t-SNE in almost every regard:\n",
    "\n",
    "* UMAP can reduce from high dimensionality to any low dimensional space. t-SNE can only reduce to 2D or 3D space.\n",
    "\n",
    "* UMAP is more deterministic. Both UMAP and t-SNE have stochastic elements in their algorithm but since UMAP uses the spectral embedding, it often gives very similar clustering results between different runs. You can observe this in the gif above. Changing the hyperparameter `n_neighbor` for example resulted in similar 2D scatter plots with a seamless transition between each plot. Whereas t-SNE's outcome might change completely from one run to the next. \n",
    "\n",
    "* UMAP runs a lot faster. t-SNE uses regular gradient descent, whereas UMAP uses stochastic gradient descent, which means it only calculates the gradient on a subset of the data, not on all of them, which also scales a lot better for very large data sets.\n",
    "\n",
    "* UMAP preserves global structure of the high dimensional space better because of how its cost function is defined. t-SNE can only preserve the local structure of the high dimensional data well.\n",
    "\n",
    "### Weaknesses of UMAP\n",
    "\n",
    "* On the website [Understanding UMAP](https://pair-code.github.io/understanding-umap/) by Andy Coenen and Adam Pearce in the chapter 'UMAP vs t-SNE, revisited' there is an example listed where t-SNE performs better than UMAP on a specific data set. Although UMAP tries to combat the curse of dimensionality by decreasing its high dimensional edge weights after the nearest neighbor exponentially and therefore trying to negate that distances between points in high dimensions tend to be very similar, UMAP fails to do so if the distances of points are very similar.\n",
    "\n",
    "* UMAP lacks interpretability. Unlike PCA, which gives the direction of the highest variances in the data, the axis of a UMAP plot are meaningless. Only the distance between the points in low dimensions are relevant.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Sources\n",
    "\n",
    "* UMAP documentation [https://umap-learn.readthedocs.io/en/latest/how_umap_works.html](https://umap-learn.readthedocs.io/en/latest/how_umap_works.html)\n",
    "\n",
    "* UMAP: Mathematical Details by 'StatQuest with Josh Starmer' [https://youtu.be/jth4kEvJ3P8](https://youtu.be/jth4kEvJ3P8)\n",
    "\n",
    "* original UMAP paper by Leland McInnes [https://arxiv.org/pdf/1802.03426.pdf](https://arxiv.org/pdf/1802.03426.pdf)\n",
    "\n",
    "* How to create gifs with gganimate in R [https://github.com/MNoichl/UMAP-examples-mammoth-/blob/master/umammoth.ipynb](https://github.com/MNoichl/UMAP-examples-mammoth-/blob/master/umammoth.ipynb)\n",
    "\n",
    "* UMAP from scratch by Nikolay Oskolkov [https://towardsdatascience.com/how-exactly-umap-works-13e3040e1668](https://towardsdatascience.com/how-exactly-umap-works-13e3040e1668)\n",
    "\n",
    "* SciPy talk by Leland McInnes (2018) [https://youtu.be/nq6iPZVUxZU](https://youtu.be/nq6iPZVUxZU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
